데이터 전처리 코드 분석

1. 훈련 세트 준비 
머신러닝 모델을 훈련시키기 위해 먼저 원본 데이터셋에서 특성(입력 데이터)과 레이블(타깃값)을 분리합니다.

# strat_train_set에서 중간 주택 가격(median_house_value) 열을 제외한 나머지를 housing 특성으로 복사
housing = strat_train_set.drop("median_house_value", axis=1)
# strat_train_set에서 중간 주택 가격 열만 housing_labels 레이블로 복사
housing_labels = strat_train_set["median_house_value"].copy()

housing = strat_train_set.drop("median_house_value", axis=1): strat_train_set 데이터프레임에서 median_house_value 컬럼(레이블)을 제거하고, 
나머지 특성들만 housing 변수에 저장합니다. axis=1은 컬럼을 기준으로 삭제하라는 의미입니다.

housing_labels = strat_train_set["median_house_value"].copy(): strat_train_set에서
 median_house_value 컬럼만 선택하여 housing_labels 변수에 복사합니다.
이렇게 분리된 housing과 housing_labels는 모델 훈련에 사용됩니다.

2. 데이터 정제 (Data Cleaning) - 결측치 처리 
머신러닝 알고리즘은 대부분 결측치가 있는 데이터를 처리하지 못하므로, 이를 해결해야 합니다. 
 예제에서는 total_bedrooms 특성에 결측치가 있는 상황을 다룹니다. 

결측치 처리 옵션:

해당 샘플(행) 제거: housing.dropna(subset=["total_bedrooms"]) 
해당 특성(열) 제거: housing.drop("total_bedrooms", axis=1) 
특정 값으로 채우기 (예: 중간값): 
median = housing["total_bedrooms"].median()
housing["total_bedrooms"].fillna(median, inplace=True)

SimpleImputer 사용: 사이킷런의 SimpleImputer는 결측치를 특정 전략에 따라 채워주는 변환기입니다. 
from sklearn.impute import SimpleImputer

# 중간값(median)으로 결측치를 채우는 Imputer 객체 생성
imputer = SimpleImputer(strategy="median")

# 수치형 특성만 선택 (ocean_proximity 제외)
housing_num = housing.select_dtypes(include=[np.number]) # SimpleImputer는 수치형 데이터에만 적용 가능 [cite: 105]

# Imputer를 훈련 데이터에 적용하여 각 특성별 중간값을 학습
imputer.fit(housing_num)

imputer.statistics_: 각 특성별로 계산된 중간값이 저장됩니다. 
X = imputer.transform(housing_num): 학습된 imputer를 사용하여 housing_num의 결측치를 중간값으로 변환한 NumPy 배열을 X에 저장합니다. 

3. 범주형 특성 다루기 
대부분의 머신러닝 알고리즘은 숫자형 데이터를 다루므로, 텍스트 기반의 범주형 특성은 수치형으로 변환해야 합니다.  예제에서는 ocean_proximity 특성을 다룹니다. 

OrdinalEncoder: 범주를 순서대로 숫자로 매핑합니다 (예: '<1H OCEAN' -> 0, 'INLAND' -> 1).  하지만 범주 간 순서가 없을 경우, 이 숫자 값의 크기가 모델에게 잘못된 정보를 줄 수 있습니다 (예: 0과 1보다 0과 4가 더 유사한 경우). 

OneHotEncoder (원-핫 인코딩): 각 범주를 새로운 이진 특성(0 또는 1)으로 변환하여 위 문제를 해결합니다. 
from sklearn.preprocessing import OneHotEncoder

# OneHotEncoder 객체 생성
cat_encoder = OneHotEncoder()
# housing_cat (범주형 특성 데이터)에 대해 원-핫 인코딩 수행
housing_cat_1hot = cat_encoder.fit_transform(housing_cat) # housing_cat은 housing[["ocean_proximity"]]와 같이 범주형 특성만 추출한 데이터입니다.

sparse=True (기본값): 결과는 SciPy 희소 행렬(sparse matrix)로 반환됩니다. 이는 대부분의 값이 0일 때 메모리를 효율적으로 사용합니다. 
sparse=False: NumPy 배열로 반환됩니다. 
cat_encoder.categories_: 인코더가 학습한 카테고리 목록을 보여줍니다. 

4. 특성 스케일링 (Feature Scaling) 
수치형 특성들의 값 범위(스케일)가 크게 다르면 모델 성능에 부정적인 영향을 줄 수 있으므로, 스케일을 맞춰주는 작업이 필요합니다.  (단, 타깃값은 스케일링하지 않습니다). 

Min-Max 스케일링 (정규화): 모든 값을 0~1 (또는 지정된 범위) 사이로 변환합니다.

수식: (x−min)/(max−min) 
MinMaxScaler: 사이킷런 변환기입니다. 
단점: 이상치(outlier)에 민감하게 반응합니다.
from sklearn.preprocessing import MinMaxScaler
min_max_scaler = MinMaxScaler(feature_range=(-1, 1)) # 값의 범위를 -1에서 1로 지정
housing_num_min_max_scaled = min_max_scaler.fit_transform(housing_num)

표준화 (Standardization): 평균을 0, 표준편차를 1이 되도록 변환합니다.
수식: (x−μ)/σ (μ: 평균, σ: 표준편차) 
StandardScaler: 사이킷런 변환기입니다. 
장점: 이상치에 상대적으로 덜 민감합니다
from sklearn.preprocessing import StandardScaler
std_scaler = StandardScaler()
housing_num_std_scaled = std_scaler.fit_transform(housing_num)

5. 변환 파이프라인 (Transformation Pipelines) 
데이터 전처리 단계가 여러 개일 경우, 이를 순서대로 실행하고 관리하기 위해 사이킷런의 Pipeline을 사용합니다.

수치형 특성 파이프라인 예시:
from sklearn.pipeline import Pipeline

# 수치형 특성에 대한 파이프라인: 결측치 중간값 대체 후 표준화
num_pipeline = Pipeline([
    ('impute', SimpleImputer(strategy="median")), # 첫 번째 단계: 결측치 처리
    ('standardize', StandardScaler()),           # 두 번째 단계: 표준화
])

Pipeline은 (이름, 변환기) 쌍의 리스트를 입력으로 받습니다. 
파이프라인의 마지막 단계를 제외한 모든 변환기는 fit_transform() 메서드를 가져야 합니다. 
make_pipeline(): 변환기의 이름을 자동으로 지정하여 파이프라인을 더 간결하게 만들 수 있습니다. 
    from sklearn.pipeline import make_pipeline
num_pipeline = make_pipeline(SimpleImputer(strategy="median"), StandardScaler())
```

ColumnTransformer: 데이터프레임의 각 컬럼(또는 컬럼 그룹)에 서로 다른 변환을 적용할 때 사용합니다.  예를 들어, 수치형 특성에는 num_pipeline을, 범주형 특성에는 다른 파이프라인(cat_pipeline)을 적용할 수 있습니다
from sklearn.compose import ColumnTransformer

num_attribs = ["longitude", "latitude", "housing_median_age", "total_rooms",
               "total_bedrooms", "population", "households", "median_income"]
cat_attribs = ["ocean_proximity"]

# 범주형 특성 파이프라인: 결측치 최빈값 대체 후 원-핫 인코딩
cat_pipeline = make_pipeline(
    SimpleImputer(strategy="most_frequent"),
    OneHotEncoder(handle_unknown="ignore")) # handle_unknown="ignore"는 테스트셋에 처음 보는 범주가 있을 경우 0으로 처리

# ColumnTransformer를 사용하여 수치형과 범주형 특성에 각각 다른 파이프라인 적용
preprocessing = ColumnTransformer([
    ("num", num_pipeline, num_attribs),       # 수치형 특성에 num_pipeline 적용
    ("cat", cat_pipeline, cat_attribs),       # 범주형 특성에 cat_pipeline 적용
])

housing_prepared = preprocessing.fit_transform(housing) # housing 데이터에 전체 전처리 파이프라인 적용
make_column_selector(): 컬럼 이름을 직접 나열하는 대신, 데이터 타입(예: np.number, object)에 따라 컬럼을 선택하여 적용할 수 있게 합니다. 

from sklearn.compose import make_column_selector
preprocessing = ColumnTransformer([
    ("num", num_pipeline, make_column_selector(dtype_include=np.number)),
    ("cat", cat_pipeline, make_column_selector(dtype_include=object)),
])

make_column_transformer(): ColumnTransformer 내부의 변환기 이름을 자동으로 지정합니다. 
6. 전체 전처리 파이프라인 구성 예시 (캘리포니아 주택 가격 데이터셋) 
PDF에서는 더 복잡한 전체 전처리 파이프라인을 구성하는 예를 보여줍니다. 여기에는 다음과 같은 내용이 포함됩니다:

비율 특성(ratio features) 추가: FunctionTransformer와 사용자 정의 함수를 사용하여 기존 특성들로부터 새로운 비율 특성(예: bedrooms_ratio = total_bedrooms / total_rooms)을 생성합니다. 

로그 변환: 분포가 한쪽으로 치우친(heavy-tailed) 특성(예: population)에 로그 함수(np.log)를 적용하여 분포를 좀 더 정규분포에 가깝게 만듭니다. 

클러스터 유사도 특성 추가: 위경도 좌표를 사용하여 K-평균(K-Means) 클러스터링으로 주요 지리적 클러스터를 찾고, 각 샘플이 이 클러스터 중심들과 얼마나 유사한지를 RBF 커널을 사용하여 새로운 특성으로 만듭니다 (사용자 정의 변환기 ClusterSimilarity 사용). 

위에서 언급된 개별 파이프라인들(비율, 로그, 지리, 범주, 기본 수치)을 ColumnTransformer를 사용하여 최종적인 preprocessing 파이프라인으로 통합합니다. 
# 예시 파이프라인의 일부 (전체 코드는 PDF 50페이지 참조 [cite: 170])

# 비율 특성 생성 파이프라인
def column_ratio(X):
    return X[:, [0]] / X[:, [1]]

def ratio_pipeline():
    return make_pipeline(
        SimpleImputer(strategy="median"),
        FunctionTransformer(column_ratio, feature_names_out=lambda func, feitaure_names_in: ["ratio"]), # feature_names_out 명시 필요할 수 있음
        StandardScaler())

# 로그 변환 파이프라인
log_pipeline = make_pipeline(
    SimpleImputer(strategy="median"),
    FunctionTransformer(np.log, feature_names_out="one-to-one"), # feature_names_out="one-to-one"은 입력과 출력 특성 이름 동일시
    StandardScaler())

# 최종 ColumnTransformer (일부)
preprocessing = ColumnTransformer([
    ("bedrooms_ratio", ratio_pipeline(), ["total_bedrooms", "total_rooms"]),
    ("log_population", log_pipeline, ["population"]),
    # ... 기타 특성 파이프라인들
    ("cat", cat_pipeline, make_column_selector(dtype_include=object))
    ],
    remainder="passthrough" # 명시되지 않은 나머지 컬럼들은 그대로 통과 (또는 다른 default_num_pipeline 적용 가능 [cite: 170])
)

housing_prepared = preprocessing.fit_transform(housing)

preprocessing.fit_transform(housing): 전체 훈련 데이터 housing에 이 복합적인 전처리 파이프라인을 적용하여 최종적으로 모델 훈련에 사용될 housing_prepared 데이터를 생성합니다. 
preprocessing.get_feature_names_out(): 변환 후 생성된 특성들의 이름을 확인할 수 있습니다. 
이러한 전처리 파이프라인을 구축함으로써, 데이터 변환 과정을 체계적으로 관리하고 새로운 데이터에 대해서도 동일한 변환을 쉽게 적용할 수 있게 됩니다. 


